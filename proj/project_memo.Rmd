---
title: "Bayesian Modeling of Polling Data"
output: pdf_document
author: Nick Ahamed
date: 10 Jan 2017
---

```{r setup, include=FALSE}
library(ggplot2)
library(tidyverse)
```

##The Problem
I am interested in using Bayesian modeling to predict how many seats Democrats will win in the 2018 House of Representative elections. This broad problem can be broken down into three composite tasks: 

1. Use past election results and polling data to generate distributions for pollster and universe bias.

2. Estimate the relationship between past polling data and number of seats.

3. Apply the bias estimates from (1) to current polling for the 2018 election to generate a polling average, and then use (2) to predict the number of seats. 

##The Data

#### Description
For this project, I have two primary sources of data: past polls and election results. The poll response that I use is the 'generic Congressional ballot.' Each pollster has a slightly different wording (and hence why we measure pollster bias), but they are all similar to: 'If the elections for the U.S. House of Representatives were being held today, which partyâ€™s candidate would you vote for in your congressional district: The Democratic candidate or the Republcian candidate?' Asking specific candidate names would be preferrable because it would test voters' preference for actual people; voters may know the name of their incumbent and feel favorable to them even though they might otherwise support the other party, for example. However, I am interested in generating a prediction for 2018 and most candidates that will be on the ballot have not been decided (and may not be until close to the election). Thus, only generic congressional ballot polls are available for 2018 and I will only use these for past elections as well. 

The past polls were taken from Real Clear Politics' database across 6 election cycles: [2006](https://realclearpolitics.com/epolls/other/2006_generic_congressional_vote-2174.html), [2008](https://www.realclearpolitics.com/epolls/other/2008_generic_congressional_vote-2173.html#polls), [2010](https://www.realclearpolitics.com/epolls/other/2010_generic_congressional_vote-2171.html#polls), [2012](https://www.realclearpolitics.com/epolls/other/2012_generic_congressional_vote-3525.html#polls), [2014](https://www.realclearpolitics.com/epolls/other/generic_congressional_vote-2170.html) and [2016](https://www.realclearpolitics.com/epolls/other/2016_generic_congressional_vote-5279.html#polls). Only polls where the year, date range, pollster, sampling universe and sample size are all known were included. Additionally, the polls' results were transformed to reflect the two-way share for Democrats (Dem/(Dem+Rep)). Time is transformed to be the rounded number of weeks between the middle day of the poll and election day. A daily model would be more precise, but would take more computation time. 

For election results, I use both the popular vote share and the seats won. These were taken from Wikipedia: [2006](https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2006), [2008](https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2008), [2010](https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2010), [2012](https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2012), [2014](https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2014), and [2016](https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2016). Again, I use Democrats' two-way vote share of the popular vote to mimic their two-way support in the polling data, and their percentage share of seats in the Congress. 

```{r, include=FALSE}
res <- read.csv("election_results.csv")
res$twoway_vote <- res$dem_vote/(res$dem_vote+res$rep_vote)
res$twoway_seat <- res$dem_seats/(res$dem_seats+res$rep_seats)

polls <- read.csv("training_dat.csv")
polls$twoway <- polls$dem/(polls$dem+polls$rep)
polls <- polls %>% 
  inner_join(res[,c("cycle","date")], by="cycle") %>%
  mutate(week = round(as.numeric((as.Date(as.character(date),  format="%m/%d/%y") - 
           as.Date(as.character(end_date),  format="%m/%d/%y")) + 
           (as.Date(as.character(end_date),  format="%m/%d/%y") - 
           as.Date(as.character(start_date),  format="%m/%d/%y"))/2)/7))
polls$n_size <- as.numeric(as.character(polls$n_size))
```

#### Exploration
First, let's explore the trends over time in each cycle. Here, each point is a poll; it's size relfects the sample size and color represents the pollster. The dashed line represents the final two-way popular vote share of Democrats.
```{r, echo=FALSE, fig.width=6, fig.height=2.5, fig.align="center"}
ggplot(data=polls, aes(x=week, y=twoway, size=sqrt(n_size), color = pollster)) + 
  geom_point(alpha=0.3) +
  theme_bw() + 
  facet_wrap(~cycle) +
  scale_x_reverse(name = "Weeks Before Election") +
  scale_y_continuous(name = "Democratic Two-way Vote Share", labels=scales::percent) + 
  geom_hline(data=res, aes(yintercept = twoway_vote), linetype="dashed") +
  guides(size=F, color = F)
```

A couple of observations from this are clear. Polls are not conducted uniformly over time between elections. For example, 2006 had a lot of polls just before the election, whereas in 2010 many were conducted nearly a year in advance. We also see that by election, some pollsters are systematically off. For example, the pink pollster in 2010 was consistently below the final election result, suggesting bias. Last, we see that there are trends in results over time. For example, in 2014 the polls got closer and closer to the true result over time. Investigating this further, we see that poll results are not normally distributed around the result **across time**, suggesting we will need a time-dependent model.  

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.width=6, fig.height=2.5, fig.align="center"}
ggplot(data=polls, aes(x=round(twoway,2))) + 
  geom_histogram() +
  theme_bw() + 
  facet_wrap(~cycle) +
  scale_x_continuous(name = "Democratic Two-way Vote Share", labels=scales::percent) + 
  ylab("Number of Polls") +
  geom_vline(data=res, aes(xintercept = twoway_vote), linetype="dashed") 
```

Let's also investigate the relationship between polls and two-way seats. While I later improve upon this through modeling, a crude measure is the average poll result within 1 week of election day, weighted by sample size. Below I plot that on the x-axis and share of seats won on the y-axis with a linear line of best fit. We see that the greater the support in final polls, the greater share of seats won. 

```{r, echo=FALSE, fig.width=2, fig.height=2, fig.align="center"}
avgs <- polls %>%
  filter(week < 2) %>%
  group_by(cycle) %>%
  summarise(avg = sum(n_size*twoway)/sum(n_size)) %>%
  inner_join(res,by="cycle")

ggplot(avgs, aes(x=avg, y=twoway_seat)) + 
  geom_point() +
  theme_bw() +
  scale_y_continuous(name = "Dems' Share of Seats Won", labels = scales::percent, limits = c(0.4,0.6)) +
  scale_x_continuous(name = "Dems' Avg Final Poll Results", labels = scales::percent, limits = c(0.4,0.6)) +
  stat_smooth(method = "lm", se=F) +
  theme(axis.title.x = element_text(size=8),
        axis.title.y = element_text(size=8))
  
```

##The Models
To answer question 1 above, I follow [Jackman (2005)](http://eppsac.utdallas.edu/files/jackman/CAJP%2040-4%20Jackman.pdf) to specify my model to estimate biases, but with an added term for sampling universe. A given poll is assumed to be normally distruted with support as the mean and the standard deviation a function of $y_i$ and sample size. This would be specified as:
$$y_i \sim \mathcal{N}(\mu_i, \sigma^2_i)$$
That poll is centered around mean $\mu_i$, which itself is a function of $\alpha_t$, the true value of support at the time the poll was taken $t_i$, $\delta_j$, the bias of pollster $j$, and $\theta_k$, the bias of sampling universe $k$. Fully specified, this is: 
$$\mu_i = \alpha_{t_i} + \delta_{j_i} + \theta_{k_i}$$
Due to the trends we see in our initial data exploration, a random walk model is appropriate. In such a model, support at time $t$ is normally distributed at time $t - 1$. 
$$ \alpha_t \sim \mathcal{N}(\alpha_{t-1}, \omega^2) $$
By including the final election results as the 'reference' for $delta$, and by using a random walk, I will be able to estimate the consistent bias of each pollster and the effect of different sampling universe. 

For these given specifications, we have the following priors: 
$$ \sigma^2_i = \sqrt{\frac{y_i(1-y_i)}{n_i}},\ \ \ \delta_j \sim \mathcal{N}(0,1),\ \ \ \theta_k \sim \mathcal{N}(0,1),\ \ \ \alpha_1 \sim \mathcal{U}(0.46, 0.56),\ \ \ \omega \sim IG(1/2,1/2)$$
$\sigma^2_i$ just follows the standard formula for standard deviation of a sample. For pollster biases ($\delta$), my prior is that there is no bias with a standard deviation large enough to capture total bias (awarding Democrats 100% when they actually had 0% support); my prior for bias from sampling universe ($\theta$) is the same. As a prior for the starting true value of support ($\alpha_1$), I use a uniform distribution over the minimum and maximum actual vote share of Democrats in the six elections analyzed. Lastly, a prior for the true standard deviation of support ($\omega$), I use the inverse gamma with an effective sample size of 1 and a prior guess of 1 like the standard deviation for $\delta$ and $\theta$.

To answer question 2 above, I will use the pollster and universe biases estimated above, and the same random walk algorithm to generate a final polling average at the time of the election, $\alpha_E$. I will then use the following model to estimate number of seats: 
$$ S_{cycle} = \beta_0 + \beta_1*\alpha_{E_{cycle}},\ \ \ cycle = 2006,...,2016 $$
My priors for this model are: 
$$ '\beta_0 \sim \mathcal{N}(0.5, 0.5),\ \ \ \beta_1 \sim \mathcal{N}(1,1)$$
$\beta_0$ here has a prior of half the seats in the House of Representatives with a standard deviation of the same. $\beta_1$ has a prior that says a 1 unit increase in $\alpha_{E_{cycle}}$ (a 100 perctange point increase in the Democrats' modeled vote share) is associated with a 100 percentage point increase in the share of seats awarded to Democrats, with a standard deviation of the same. 

To answer question 3, I will use the same random walk algorithm already mentioned, along with the pollster and universe biases and distributions to generate a polling average for today. I will then use this $\alpha$ with the coefficients estimated in the second model to predict the number of seats Democrats will win in 2018. 